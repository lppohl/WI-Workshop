---
title: Home
layout: page
---

# Social Science and Language Models 
### Methods and theory to responsible research on and with Language technologies

<p> In recent years, language models have seen improved performance in tasks like translation, sorting, and text generation, which has led to their integration into a variety of fields, such as medical contexts, software engineering but also social science. Parallel to this technological proliferation, the emerging field of Responsible AI research has revealed various socio-technical biases in language models which result in discrimination based on attributes such as ethnicity, gender, and more. These findings force both social scientists and computer scientists who are integrating these tools into their research, to reflect how they can detect and mitigate potentiallyÂ  biased outcomes. By doing so, they contribute to an expanding body of literature that critiques how discrimination is conceptualized, how bias measurements are operationalized, and how existing bias benchmarks are constructed. These issues stem from a lack of genuine interdisciplinary collaboration between NLP researchers and researchers from various social science disciplines.

This workshop is meant to provide the space for interdisciplinary exchange toward responsible research on and with language models.

------

### Event Details

**Location** 
[Kassenhalle Weizenbaum Institut](https://www.weizenbaum-institut.de/) and hybrid

**Date**
3rd and 4th of April.

------
### Speaker

*to be determined*
